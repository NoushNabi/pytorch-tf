{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from squeezenet import SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "model = SqueezeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"./squeezenet.ckpt\")\n",
    "input_image = model.image\n",
    "classifier = model.classifier\n",
    "features = model.features\n",
    "# old way\n",
    "#new_saver = tf.train.import_meta_graph('squeezenet.ckpt.meta')\n",
    "#new_saver.restore(sess, \"./squeezenet.ckpt\")\n",
    "#input_image = sess.graph.get_operation_by_name('Placeholder').outputs[0]\n",
    "#classifier = sess.graph.get_operation_by_name('classifier/Reshape').outputs[0]\n",
    "#features = sess.graph.get_operation_by_name('features/layer12/concat').outputs[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "\n",
    "with open('labels.txt') as fp:\n",
    "    labels = [c[:-2].split(':')[1] for c in fp.readlines()]\n",
    "def get_img(filename):\n",
    "    vec = np.array(Image.open(filename))\n",
    "    vec = imresize(vec,(224,224)).astype(np.float32)/255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    vec = (vec-mean)/std\n",
    "    return vec\n",
    "    \n",
    "img_dir = '.'\n",
    "img_names = [x for x in os.listdir(img_dir) if 'jpeg' in x.lower()]\n",
    "imgs = [get_img(os.path.join(img_dir,x)) for x in img_names]\n",
    "\n",
    "scores = sess.run(classifier,feed_dict={input_image:np.array(imgs).reshape([-1,224,224,3])})\n",
    "for idx,s in enumerate(np.argmax(scores,1)):\n",
    "    print(img_names[idx],labels[s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "input_data = torch.FloatTensor(np.transpose(np.array(imgs),[0,3,1,2]))\n",
    "model.eval()\n",
    "pyt_scores = model(Variable(input_data))\n",
    "scores_ref = pyt_scores.data.numpy()\n",
    "def rel_error(x, y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "print(rel_error(scores,scores_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
